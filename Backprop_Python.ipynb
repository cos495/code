{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation learning for multilayer perceptron\n",
    "\n",
    "    @author      Donghun Lee\n",
    "    @rev.date    2017/02/11\n",
    "\n",
    "Python 2.7 port of Backprop.ipynb Julia code by Prof. Sebastian Seung\n",
    "\n",
    "- Porting focused to maximize comparable readability of code and results with original Julia code\n",
    "- Note: In this code, label 0 has index 0. (Python indexing starts from 0, Julia from 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home=\"data\")\n",
    "def trainfeatures(i):\n",
    "    return np.float64(mnist.data[i, :])\n",
    "def trainlabel(i):\n",
    "    return mnist.target[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):                # logistic function activation (replace to define your own activation function)\n",
    "    return np.divide(1, (1 + np.exp(-x)))\n",
    "def df(y):               # derivative of f composed with inverse of f\n",
    "    return np.multiply(y, 1-y)\n",
    "\n",
    "m = 60000                # number of examples in training set\n",
    "\n",
    "n0 = 784                 # widths of layers\n",
    "n1 = 25\n",
    "n2 = 10  \n",
    "\n",
    "eta = 0.1                # learning rate parameter\n",
    "epsinit = 0.01           # magnitude of initial conditions for synaptic weights\n",
    "\n",
    "# two fully connected synaptic layers\n",
    "W1 = epsinit*np.random.randn(n1,n0)\n",
    "W2 = epsinit*np.random.randn(n2,n1)\n",
    "\n",
    "# biases\n",
    "b1 = epsinit*np.random.randn(n1)\n",
    "b2 = epsinit*np.random.randn(n2)\n",
    "\n",
    "tmax = 600000            # maximum number of learning updates\n",
    "tshow = 1000             # how often to pause for visualization\n",
    "errsq = np.zeros(tmax)\n",
    "errcl = np.zeros(tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "fig_size = (12,12)                           # you may need to change the numbers to fit your screen\n",
    "for t in xrange(tmax):\n",
    "    i = int(np.ceil(m*np.random.rand()))     # choose randomly from the training set\n",
    "    x0 = trainfeatures(int(i))/255.0         # (Python 2.x division)\n",
    "    y = np.zeros(n2)\n",
    "    y[int(trainlabel(i))] = 1                # use label to create desired output in one-hot representation\n",
    "                                             # (Python array indexing is from 0)\n",
    "\n",
    "    # forward pass   \n",
    "    x1 = f(np.dot(W1,x0)+b1)\n",
    "    x2 = f(np.dot(W2,x1)+b2)\n",
    "    # error computation\n",
    "    errsq[t] = sum(np.power((y-x2), 2))\n",
    "    delta2 = np.multiply((y-x2),df(x2))\n",
    "    errcl[t] = float(np.argmax(x2) != trainlabel(i))\n",
    "    # backward pass\n",
    "    delta1 = np.multiply(np.dot(W2.T, delta2), df(x1))\n",
    "    # learning updates\n",
    "    W2 += eta*np.outer(delta2, x1)\n",
    "    W1 += eta*np.outer(delta1, x0)\n",
    "    b2 += eta*delta2\n",
    "    b1 += eta*delta1\n",
    "\n",
    "    if t % tshow == 0:    # visualization every tshow steps\n",
    "        avgerrsq = np.divide( np.cumsum(errsq[0:t]), np.arange(1,t+1) )\n",
    "        avgerrcl = np.divide( np.cumsum(errcl[0:t]), np.arange(1,t+1) )\n",
    "        \n",
    "        fig = plt.figure(figsize=fig_size)\n",
    "        gs = gridspec.GridSpec(6,5, wspace=0.3, hspace=0.1)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0,0])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(\"x0 at t={}\".format(t))\n",
    "        ax.imshow(x0.reshape(28,28), origin='upper', interpolation='nearest') \n",
    "\n",
    "        ax = fig.add_subplot(gs[0,1])\n",
    "        ax.bar(range(len(x1)), x1)\n",
    "        ax.set_ylabel(\"x1\")\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.grid()\n",
    "\n",
    "        ax = fig.add_subplot(gs[0,2])\n",
    "        ax.bar(range(len(x2)), x2)\n",
    "        ax.set_ylabel(\"x2\")\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_xticks(range(0,10))\n",
    "        ax.grid()\n",
    "\n",
    "        ax = fig.add_subplot(gs[0,3:5])\n",
    "        ax.plot(avgerrsq, label=\"squared\")\n",
    "        ax.plot(avgerrcl, label=\"class\")\n",
    "        ax.set_ylabel(\"error\")\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "\n",
    "        for i in range(n1):\n",
    "            ax = fig.add_subplot(gs[1 + i / 5, i % 5])\n",
    "            ax.axis('off')\n",
    "            ax.imshow(W1.T.reshape(28,28,n1)[:,:,i], origin='upper', interpolation='nearest') \n",
    "        \n",
    "        # plot_image(W1.T.reshape(28,28,n1)[:,:,1])\n",
    "\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(0.01)\n",
    "        display.clear_output(wait=True)\n",
    "        plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
